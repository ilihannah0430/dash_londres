{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05a5dc66-c417-4d6e-9d14-e62b1c4dfdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-d9273cc6a586>:233: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-d9273cc6a586>:234: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-18-d9273cc6a586>:321: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice\n",
      "\n",
      "<ipython-input-18-d9273cc6a586>:400: DeprecationWarning:\n",
      "\n",
      "*scatter_mapbox* is deprecated! Use *scatter_map* instead. Learn more at: https://plotly.com/python/mapbox-to-maplibre/\n",
      "\n",
      "<ipython-input-18-d9273cc6a586>:404: FutureWarning:\n",
      "\n",
      "The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8084a73eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import folium\n",
    "from folium import Map, Marker, Popup, IFrame\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import json\n",
    "import dash_table\n",
    "from sklearn.cluster import KMeans  # only import once\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialisation de l'application Dash\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Charger les données\n",
    "medianes = pd.read_csv('land-registry-house-prices-borough.csv')\n",
    "age_batiment = pd.read_csv(\"london_houses.csv\")\n",
    "recycl = pd.read_csv(\"Household-rcycling-borough.csv\")\n",
    "\n",
    "# Nettoyage des données\n",
    "medianes[\"Year\"] = medianes[\"Year\"].astype(str).str.extract(r'(\\d{4})').astype(int)\n",
    "medianes[\"Value\"] = medianes[\"Value\"].str.replace(\",\", \"\").astype(float)\n",
    "age_batiment = age_batiment.rename(columns={'Price (£)': 'Price'})\n",
    "\n",
    "# Moyenne des taux de recyclage par quartier\n",
    "moyenne_recyclage = recycl.groupby(\"Area\")[\"Recycling_Rates\"].mean().reset_index()\n",
    "moyenne_recyclage = moyenne_recyclage.sort_values(by=\"Recycling_Rates\", ascending=False)\n",
    "\n",
    "london_boroughs_coords = {\n",
    "    \"City of London\": [51.51279, -0.09184],\n",
    "    \"Barking and Dagenham\": [51.5362, 0.1275],\n",
    "    \"Barnet\": [51.6255, -0.1514],\n",
    "    \"Bexley\": [51.455, 0.1502],\n",
    "    \"Brent\": [51.5588, -0.2817],\n",
    "    \"Bromley\": [51.4054, 0.0144],\n",
    "    \"Camden\": [51.5416, -0.1431],\n",
    "    \"Croydon\": [51.3751, -0.0982],\n",
    "    \"Ealing\": [51.513, -0.3086],\n",
    "    \"Enfield\": [51.6623, -0.118],\n",
    "    \"Greenwich\": [51.4892, 0.0648],\n",
    "    \"Hackney\": [51.553, -0.06],\n",
    "    \"Hammersmith and Fulham\": [51.4927, -0.2213],\n",
    "    \"Haringey\": [51.5908, -0.1097],\n",
    "    \"Harrow\": [51.5788, -0.3337],\n",
    "    \"Havering\": [51.5761, 0.1837],\n",
    "    \"Hillingdon\": [51.5352, -0.4482],\n",
    "    \"Hounslow\": [51.4746, -0.3702],\n",
    "    \"Islington\": [51.5441, -0.1026],\n",
    "    \"Kensington and Chelsea\": [51.4995, -0.1936],\n",
    "    \"Kingston upon Thames\": [51.4123, -0.3007],\n",
    "    \"Lambeth\": [51.488, -0.1154],\n",
    "    \"Lewisham\": [51.4415, -0.0117],\n",
    "    \"Merton\": [51.4098, -0.2102],\n",
    "    \"Newham\": [51.5255, 0.0352],\n",
    "    \"Redbridge\": [51.5886, 0.0822],\n",
    "    \"Richmond upon Thames\": [51.4452, -0.3294],\n",
    "    \"Southwark\": [51.4979, -0.0758],\n",
    "    \"Sutton\": [51.359, -0.191],\n",
    "    \"Tower Hamlets\": [51.5155, -0.0371],\n",
    "    \"Waltham Forest\": [51.5884, -0.0112],\n",
    "    \"Wandsworth\": [51.4576, -0.191],\n",
    "    \"Westminster\": [51.4975, -0.1357],\n",
    "}\n",
    "\n",
    "def generate_recycling_map():\n",
    "    # Calcul du taux moyen de recyclage par quartier\n",
    "    avg_recycling = recycl.groupby(\"Area\")[\"Recycling_Rates\"].mean().to_dict()\n",
    "\n",
    "    # Création de la carte centrée sur Londres\n",
    "    m = folium.Map(location=[51.5074, -0.1278], zoom_start=10)\n",
    "\n",
    "    # Fonction pour déterminer la couleur en fonction du taux de recyclage\n",
    "    def get_recycling_color(rate):\n",
    "        if rate <= 15:\n",
    "            return \"red\"  # Faible\n",
    "        elif rate <= 30:\n",
    "            return \"orange\"  # Moyenne\n",
    "        elif rate <= 45:\n",
    "            return \"yellow\"  # Élevée\n",
    "        else:\n",
    "            return \"green\"  # Très élevée\n",
    "\n",
    "    # Ajout de marqueurs pour chaque quartier\n",
    "    for borough, coords in london_boroughs_coords.items():\n",
    "        if borough in avg_recycling:\n",
    "            mean_rate = avg_recycling[borough]\n",
    "            \n",
    "            # Création du graphique d’évolution avec Plotly\n",
    "            borough_data = recycl[recycl[\"Area\"] == borough]\n",
    "            fig = px.line(\n",
    "                borough_data,\n",
    "                x=\"Year\",\n",
    "                y=\"Recycling_Rates\",\n",
    "                title=f\"Évolution du taux de recyclage à {borough}\",\n",
    "                labels={\"Year\": \"Année\", \"Recycling_Rates\": \"Taux de recyclage (%)\"},\n",
    "            )\n",
    "\n",
    "            # Conversion du graphique en HTML\n",
    "            iframe = IFrame(fig.to_html(full_html=False, include_plotlyjs='cdn'), width=500, height=300)\n",
    "            popup = Popup(iframe, max_width=500)\n",
    "\n",
    "            # Ajout d’un cercle sur la carte avec la couleur selon le taux de recyclage\n",
    "            folium.CircleMarker(\n",
    "                location=coords,\n",
    "                radius=10,\n",
    "                color=\"blue\",\n",
    "                fill=True,\n",
    "                fill_color=get_recycling_color(mean_rate),  # Couleur selon le taux\n",
    "                fill_opacity=0.6,\n",
    "                popup=popup,\n",
    "            ).add_to(m)\n",
    "\n",
    "    # Ajout d’une légende manuelle\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; width: 150px; height: 120px; \n",
    "                background-color: white; z-index:9999; font-size:14px;\n",
    "                padding: 10px; border-radius: 5px;\n",
    "                box-shadow: 2px 2px 5px rgba(0,0,0,0.3);\">\n",
    "        <b>Légende :</b><br>\n",
    "        <i class=\"fa fa-circle\" style=\"color:red\"></i> Faible (≤15%)<br>\n",
    "        <i class=\"fa fa-circle\" style=\"color:orange\"></i> Moyenne (≤30%)<br>\n",
    "        <i class=\"fa fa-circle\" style=\"color:yellow\"></i> Élevée (≤45%)<br>\n",
    "        <i class=\"fa fa-circle\" style=\"color:green\"></i> Très élevée (>45%)<br>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    # Sauvegarde de la carte en HTML\n",
    "    map_path = \"carte_recyclage.html\"\n",
    "    m.save(map_path)\n",
    "    \n",
    "    return map_path\n",
    "\n",
    "Prix2 = pd.read_csv(\"London.csv\")\n",
    "# Nettoyer les noms de colonnes pour éviter les erreurs avec LightGBM\n",
    "Prix2.columns = Prix2.columns.str.replace(r'[^A-Za-z0-9_]', '_', regex=True)\n",
    "\n",
    "#pour la section 3\n",
    "\n",
    "def generate_cluster_repartition_and_intervals(kmeans_model, cluster_column_name):\n",
    "    cluster_centroids = kmeans_model.cluster_centers_\n",
    "    cluster_intervals = sorted(cluster_centroids.flatten())  # Tri des centroids pour obtenir des intervalles\n",
    "    \n",
    "    # Ajout des bornes minimales et maximales pour créer les intervalles de prix\n",
    "    min_price, max_price = Prix2['Price'].min(), Prix2['Price'].max()\n",
    "    cluster_intervals = [min_price] + cluster_intervals + [max_price]\n",
    "    \n",
    "    # Répartition des données dans chaque cluster\n",
    "    cluster_repartition = Prix2[cluster_column_name].value_counts().sort_index()\n",
    "\n",
    "    # Créer une liste des intervalles de prix\n",
    "    price_intervals = [f\"{cluster_intervals[i]} - {cluster_intervals[i + 1]}\" for i in range(len(cluster_intervals) - 1)]\n",
    "\n",
    "    # DataFrame pour la répartition des clusters et des intervalles de prix\n",
    "    cluster_repartition_df = pd.DataFrame({\n",
    "        \"Cluster\": cluster_repartition.index,\n",
    "        \"Count\": cluster_repartition.values,\n",
    "        \"Price Interval\": price_intervals[:len(cluster_repartition)]  # Ajuster la taille des intervalles\n",
    "    })\n",
    "    \n",
    "    return cluster_repartition_df\n",
    "\n",
    "X = Prix2[['Price']] \n",
    "\n",
    "# Create the KMeans model with 5 clusters\n",
    "kmeans_5 = KMeans(n_clusters=5, random_state=42)\n",
    "Prix2['Price Category (5 Clusters)'] = kmeans_5.fit_predict(X)\n",
    "# For kmeans_4 with 4 clusters\n",
    "kmeans_4 = KMeans(n_clusters=4, random_state=42)\n",
    "Prix2['Price Category (4 Clusters)'] = kmeans_4.fit_predict(X)\n",
    "\n",
    "# For kmeans_6 with 6 clusters\n",
    "kmeans_6 = KMeans(n_clusters=6, random_state=42)\n",
    "Prix2['Price Category (6 Clusters)'] = kmeans_6.fit_predict(X)\n",
    "\n",
    "# For kmeans_7 with 7 clusters\n",
    "kmeans_7 = KMeans(n_clusters=7, random_state=42)\n",
    "Prix2['Price Category (7 Clusters)'] = kmeans_7.fit_predict(X)\n",
    "\n",
    "# For kmeans_8 with 8 clusters\n",
    "kmeans_8 = KMeans(n_clusters=8, random_state=42)\n",
    "Prix2['Price Category (8 Clusters)'] = kmeans_8.fit_predict(X)\n",
    "\n",
    "\n",
    "\n",
    "# 1. Générer les tableaux pour chaque nombre de clusters\n",
    "cluster_4_df = generate_cluster_repartition_and_intervals(kmeans_4, 'Price Category (4 Clusters)')\n",
    "cluster_5_df = generate_cluster_repartition_and_intervals(kmeans_5, 'Price Category (5 Clusters)')\n",
    "cluster_6_df = generate_cluster_repartition_and_intervals(kmeans_6, 'Price Category (6 Clusters)')\n",
    "cluster_7_df = generate_cluster_repartition_and_intervals(kmeans_7, 'Price Category (7 Clusters)')\n",
    "cluster_8_df = generate_cluster_repartition_and_intervals(kmeans_8, 'Price Category (8 Clusters)')\n",
    "\n",
    "\n",
    "cluster_data = {\n",
    "    \"4 Clusters\": cluster_4_df,\n",
    "    \"5 Clusters\": cluster_5_df,\n",
    "    \"6 Clusters\": cluster_6_df,\n",
    "    \"7 Clusters\": cluster_7_df,\n",
    "    \"8 Clusters\": cluster_8_df\n",
    "}\n",
    "\n",
    "# Répartition des données d'apprentissage pour chaque catégorie de prix (clusters)\n",
    "y_4_clusters = Prix2['Price Category (4 Clusters)']\n",
    "y_5_clusters = Prix2['Price Category (5 Clusters)']\n",
    "y_6_clusters = Prix2['Price Category (6 Clusters)']\n",
    "y_7_clusters = Prix2['Price Category (7 Clusters)']\n",
    "y_8_clusters = Prix2['Price Category (8 Clusters)']\n",
    "\n",
    "\n",
    "# Sélectionner les colonnes que vous souhaitez inclure dans X\n",
    "features = ['House_Type', 'Area_in_sq_ft', 'No__of_Bedrooms', \n",
    "            'No__of_Bathrooms', 'No__of_Receptions', 'Location']\n",
    "\n",
    "X = Prix2[features]\n",
    "\n",
    "# Encoder les variables catégorielles (exemple pour 'House_Type' et 'Location')\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Applique l'encodage sur les variables catégorielles\n",
    "X['House_Type'] = label_encoder.fit_transform(X['House_Type'])\n",
    "X['Location'] = label_encoder.fit_transform(X['Location'])\n",
    "\n",
    "# Pour 'Property_Name', vous pouvez faire de même si vous voulez l'utiliser aussi.\n",
    "# Notez que l'encodage de 'Property_Name' peut ne pas être utile selon la nature de cette variable,\n",
    "# mais si vous voulez l'utiliser, vous pouvez aussi appliquer un encodage similaire.\n",
    "\n",
    "# Séparation des données en train et test pour les différentes catégories de prix (clusters)\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = train_test_split(X, y_4_clusters, test_size=0.2, random_state=42)\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = train_test_split(X, y_5_clusters, test_size=0.2, random_state=42)\n",
    "X_train_6, X_test_6, y_train_6, y_test_6 = train_test_split(X, y_6_clusters, test_size=0.2, random_state=42)\n",
    "X_train_7, X_test_7, y_train_7, y_test_7 = train_test_split(X, y_7_clusters, test_size=0.2, random_state=42)\n",
    "X_train_8, X_test_8, y_train_8, y_test_8 = train_test_split(X, y_8_clusters, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèles de classification\n",
    "models = {\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=1000, max_depth=10, learning_rate=0.1, random_state=42),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=1000, max_depth=10, learning_rate=0.1, random_state=42, verbose=-1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "}\n",
    "\n",
    "# Stockage des performances\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    for decoupage, X_train, X_test, y_train, y_test in [\n",
    "        (\"4 Clusters\", X_train_4, X_test_4, y_train_4, y_test_4),\n",
    "        (\"5 Clusters\", X_train_5, X_test_5, y_train_5, y_test_5),\n",
    "        (\"6 Clusters\", X_train_6, X_test_6, y_train_6, y_test_6),\n",
    "        (\"7 Clusters\", X_train_7, X_test_7, y_train_7, y_test_7),\n",
    "        (\"8 Clusters\", X_train_8, X_test_8, y_train_8, y_test_8)\n",
    "    ]:\n",
    "        # Entraînement\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Évaluation\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        results.append((name, decoupage, acc))\n",
    "\n",
    "# Création d'un DataFrame pour stocker les résultats\n",
    "df_results = pd.DataFrame(results, columns=['Modèle', 'Découpage', 'Accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Entraîner le modèle RandomForest sur les données des 5 clusters\n",
    "rf_model_5 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "# Extraire l'importance des variables\n",
    "feature_importances = rf_model_5.feature_importances_\n",
    "\n",
    "# Créer un DataFrame pour afficher les résultats\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_5.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Créer un graphique de l'importance des variables\n",
    "importance_fig = px.bar(importance_df, x='Feature', y='Importance', \n",
    "                        title=\"Importance des variables pour la classification avec Random Forest (5 Clusters)\",\n",
    "                        labels={'Importance': 'Importance', 'Feature': 'Variable'},\n",
    "                        color='Importance', color_continuous_scale='Viridis')\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "prix_moyen = pd.read_csv(\"moyennes_prix.csv\", sep=\";\")\n",
    "prix_moyen = prix_moyen.drop(columns=prix_moyen.columns[2])  # Garde toutes les colonnes sauf la première\n",
    "# Extraire les années uniques en supprimant le texte \"Year ending XXX\"\n",
    "prix_moyen_annees=prix_moyen.drop(columns=prix_moyen.columns[0])\n",
    "prix_moyen_annees=prix_moyen_annees.drop(columns=prix_moyen_annees.columns[0])\n",
    "# Extraire les années uniques en supprimant \"Year ending XXX\"\n",
    "prix_moyen_annees.columns = prix_moyen_annees.columns.str.extract(r'(\\d{4})')[0]\n",
    "# Remplacer les espaces insécables (code Unicode) par des espaces simples ou rien\n",
    "prix_moyen_annees = prix_moyen_annees.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# Convertir les valeurs en numérique, forcer la conversion en NaN si nécessaire\n",
    "prix_moyen_annees = prix_moyen_annees.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convertir les valeurs en numérique pour éviter les erreurs de type\n",
    "prix_moyen_annees = prix_moyen_annees.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Vérifier le nombre de colonnes\n",
    "n_colonnes = prix_moyen_annees.shape[1]\n",
    "\n",
    "data_array = prix_moyen_annees.to_numpy()\n",
    "# Calculer la moyenne tous les 3 colonnes\n",
    "moyennes = np.nanmean(data_array.reshape(prix_moyen_annees.shape[0], -1, 4), axis=2)\n",
    "\n",
    "# Générer les noms des nouvelles colonnes (en supposant que les années commencent à 1996)\n",
    "annees = list(range(1996, 1996 + moyennes.shape[1]))  \n",
    "new_columns = [f\"moyenne_{annee}\" for annee in annees]\n",
    "\n",
    "# Créer le DataFrame avec les moyennes\n",
    "moyennes_annuelles = pd.DataFrame(moyennes, columns=new_columns)\n",
    "\n",
    "# Ajouter les colonnes \"Code\" et \"Area\" du DataFrame original\n",
    "moyennes_annuelles.insert(0, \"Code\", prix_moyen[\"Code\"])\n",
    "moyennes_annuelles.insert(1, \"Area\", prix_moyen[\"Area\"])\n",
    "\n",
    "recyclage=pd.read_csv(\"Household-rcycling-borough.csv\")\n",
    "dispo=pd.read_csv(\"Dclg-affordable-housing-borough.csv\")\n",
    "def transform_year(year):\n",
    "    # Si l'année suit le format \"YYYY-YY\" (comme \"2003-04\")\n",
    "    if isinstance(year, str) and '-' in year:\n",
    "        return int(year.split(\"-\")[0])\n",
    "    # Si l'année suit le format \"YYYY/YY\" (comme \"2003/04\")\n",
    "    elif isinstance(year, str) and '/' in year:\n",
    "        return int(year.split(\"/\")[0])\n",
    "    else:\n",
    "        return year  # retourne la valeur d'origine en cas de format inconnu\n",
    "\n",
    "# Transformation des années pour dispo uniquement\n",
    "dispo['Year'] = dispo['Year'].apply(transform_year)\n",
    "\n",
    "# Transformation des années pour recyclage\n",
    "recyclage['Year'] = recyclage['Year'].apply(transform_year)\n",
    "\n",
    "# Pivoté les données du recyclage pour que les années deviennent des colonnes\n",
    "recyclage_pivot = recyclage.pivot_table(index=['Code', 'Area'], columns='Year', values='Recycling_Rates', aggfunc='mean')\n",
    "\n",
    "# Supprimer les virgules dans 'Affordable Housing Supply'\n",
    "dispo['Affordable Housing Supply'] = dispo['Affordable Housing Supply'].str.replace(',', '')\n",
    "\n",
    "# Convertir la colonne en numérique\n",
    "dispo['Affordable Housing Supply'] = pd.to_numeric(dispo['Affordable Housing Supply'], errors='coerce')\n",
    "\n",
    "# Pivot des données : la colonne Year devient les colonnes et les valeurs sont dans 'Affordable Housing Supply'\n",
    "dispo_pivoted = dispo.pivot_table(index=['Code', 'Area'], columns='Year', values='Affordable Housing Supply', aggfunc='mean')\n",
    "# Renommer les colonnes pour qu'elles commencent par 'dispo_'\n",
    "dispo_pivoted.columns = [f\"dispo_{annee}\" for annee in dispo_pivoted.columns]\n",
    "recyclage_pivot.columns = [f\"recly_{annee}\" for annee in recyclage_pivot.columns]\n",
    "df = pd.merge(moyennes_annuelles,recyclage_pivot, on=['Code', 'Area'], how='left')\n",
    "df2=pd.merge(df,dispo_pivoted, on=['Code', 'Area'], how='left')\n",
    "df2 = df2.dropna()\n",
    "\n",
    "# Associer les coordonnées aux boroughs de Londres\n",
    "df2[\"Latitude\"] = df2[\"Area\"].map(lambda x: london_boroughs_coords.get(x, [None, None])[0])\n",
    "df2[\"Longitude\"] = df2[\"Area\"].map(lambda x: london_boroughs_coords.get(x, [None, None])[1])\n",
    "\n",
    "df2 = df2.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
    "\n",
    "# Liste des colonnes à exclure (exemple : identifiants, noms, etc.)\n",
    "colonnes_a_exclure = [\"Code\", \"Area\", \"Latitude\", \"Longitude\"]  \n",
    "\n",
    "# Sélectionner toutes les autres colonnes\n",
    "features = df2.columns.difference(colonnes_a_exclure)  \n",
    "\n",
    "# Créer le DataFrame pour le clustering\n",
    "df_cluster = df2[features].dropna()\n",
    "\n",
    "# Convertir toutes les colonnes en numérique, en ignorant les erreurs (coercition en NaN si non convertible)\n",
    "df_cluster = df_cluster.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Normalisation des données\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Appliquer K-Means avec le bon nombre de clusters\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)  # Remplace 4 par le bon k trouvé\n",
    "df_cluster['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Ajouter les clusters au DataFrame principal\n",
    "df2['Cluster'] = df_cluster['Cluster']\n",
    "\n",
    "fig_clusters = px.scatter_mapbox(df2, lat=\"Latitude\", lon=\"Longitude\", color=\"Cluster\",\n",
    "                        hover_name=\"Area\", zoom=10, mapbox_style=\"carto-positron\")\n",
    "\n",
    "\n",
    "cluster_means = df2.groupby(\"Cluster\").mean()\n",
    "\n",
    "# Sélection des colonnes des prix\n",
    "prix_cols = [col for col in df2.columns if \"moyenne_\" in col]\n",
    "\n",
    "# Moyenne des prix par année et par cluster\n",
    "prix_cluster = df2.groupby(\"Cluster\")[prix_cols].mean().T\n",
    "\n",
    "\n",
    "fig_prix_cluster = go.Figure()\n",
    "\n",
    "for cluster in prix_cluster.columns:\n",
    "    fig_prix_cluster.add_trace(go.Scatter(\n",
    "        x=prix_cluster.index.str.replace(\"moyenne_\", \"\"), \n",
    "        y=prix_cluster[cluster],\n",
    "        mode='lines',\n",
    "        name=f'Cluster {cluster}'\n",
    "    ))\n",
    "\n",
    "fig_prix_cluster.update_layout(\n",
    "    title=\"Évolution des prix moyens par cluster\",\n",
    "    xaxis_title=\"Année\",\n",
    "    yaxis_title=\"Prix moyen\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "\n",
    "# Sélection des colonnes de disponibilité\n",
    "dispo_cols = [col for col in df2.columns if \"dispo_\" in col]\n",
    "\n",
    "# Moyenne des disponibilités par année et par cluster\n",
    "dispo_cluster = df2.groupby(\"Cluster\")[dispo_cols].mean().T\n",
    "\n",
    "# Créer une figure Plotly pour les disponibilités\n",
    "fig_dispo_cluster = go.Figure()\n",
    "\n",
    "for cluster in dispo_cluster.columns:\n",
    "    fig_dispo_cluster.add_trace(go.Scatter(\n",
    "        x=dispo_cluster.index.str.replace(\"dispo_\", \"\"), \n",
    "        y=dispo_cluster[cluster],\n",
    "        mode='lines',\n",
    "        name=f'Cluster {cluster}'\n",
    "    ))\n",
    "\n",
    "fig_dispo_cluster.update_layout(\n",
    "    title=\"Évolution de la disponibilité des logements par cluster\",\n",
    "    xaxis_title=\"Année\",\n",
    "    yaxis_title=\"Disponibilité moyenne\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "\n",
    "# Sélection des colonnes de recyclage\n",
    "recy_cols = [col for col in df2.columns if \"recly_\" in col]\n",
    "\n",
    "# Moyenne des taux de recyclage par année et par cluster\n",
    "recy_cluster = df2.groupby(\"Cluster\")[recy_cols].mean().T\n",
    "\n",
    "# Créer une figure Plotly pour le taux de recyclage\n",
    "fig_recy_cluster = go.Figure()\n",
    "\n",
    "for cluster in recy_cluster.columns:\n",
    "    fig_recy_cluster.add_trace(go.Scatter(\n",
    "        x=recy_cluster.index.str.replace(\"recly_\", \"\"), \n",
    "        y=recy_cluster[cluster],\n",
    "        mode='lines',\n",
    "        name=f'Cluster {cluster}'\n",
    "    ))\n",
    "\n",
    "fig_recy_cluster.update_layout(\n",
    "    title=\"Évolution du taux de recyclage par cluster\",\n",
    "    xaxis_title=\"Année\",\n",
    "    yaxis_title=\"Taux de recyclage moyen\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Layout de l'application Dash\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Analyse des logements à Londres\"),\n",
    "        html.P(\"Ce projet vise à analyser le marché du logement à Londres en exploitant diverses sources de données. L'objectif est de comprendre l'évolution des prix, des ventes et des caractéristiques des logements dans les différents quartiers (33) de la ville et d'identifier des comportements similaires entre quartiers.\"),\n",
    "    dcc.Markdown('''\n",
    "    L'analyse s'est faite en plusieurs étapes : \n",
    "\n",
    "    - **Statistiques descriptives** : étude de l'évolution des prix par quartier, du nombre de ventes et des potentiels facteurs ayant une influence sur le prix des logements.\n",
    "    - **Clustering** : L'objectif ici est de regrouper des quartiers ensemble autour de certaines caractéristiques.\n",
    "    - **Classification** : identification des caractéristiques permettant de prédire l’appartenance d’un quartier à une tranche de prix donnée.\n",
    "\n",
    "    Les données utilisées proviennent de sources officielles et ouvertes, notamment :\n",
    "    - **Housing-sales-borough.csv** : ventes immobilières par quartier (1995-2014).\n",
    "    - **land-registry-house-prices-borough.csv** : prix médians des logements (1995-2017).\n",
    "    - **Dclg-affordable-housing-borough.csv** : logements abordables construits par année et quartier.\n",
    "    - **Household-recycling-borough.csv** : taux de recyclage par quartier (2003-2023).\n",
    "    - **Tenure-households-borough.csv & Tenure-population-borough.csv** : répartition des logements et population par type d’occupation (2008-2018).\n",
    "    - **London.csv & London_houses.csv** : caractéristiques détaillées des logements londoniens (prix, superficie, nombre de chambres, etc.).\n",
    "\n",
    "    Cette analyse a pour objectif global de comprendre les dynamiques du marché des logements londoniens.\n",
    "    '''),\n",
    "\n",
    "    # Section 1 : Statistiques descriptives\n",
    "    html.H2(\"1. Statistiques descriptives\"),\n",
    "\n",
    "    # 1.1 Évolution des prix des logements\n",
    "    html.H3(\"1.1 Évolution des prix des logements\"),\n",
    "    html.P([\n",
    "    \"Regardons l'évolution du prix moyen des logements à Londres d'année en année depuis 1995. Voici le jeu de données utilisé : \",\n",
    "    html.A(\"land-registry-house-prices-borough.csv\", \n",
    "           href=\"https://data.london.gov.uk/download/average-house-prices/f01b1cc7-6daa-4256-bd6c-94d8c83ee000/land-registry-house-prices-borough.xls\", \n",
    "           target=\"_blank\")\n",
    "]),\n",
    "\n",
    "    dcc.Graph(id='prix-maisons-graph'),  # Graphique 1\n",
    "\n",
    "    html.P(\"Sélectionnez un quartier pour voir l'évolution des prix.\"),\n",
    "    dcc.Dropdown(\n",
    "        id='dropdown-quartier',\n",
    "        options=[{'label': area, 'value': area} for area in medianes[\"Area\"].unique()],\n",
    "        value='London',  # Quartier par défaut\n",
    "        style={'width': '50%'}\n",
    "    ),\n",
    "    dcc.Graph(id='graph-quartier'),  # Graphique 2\n",
    "\n",
    "    html.P(\"On observe une augmentation (attendue) des prix des logements. On peut noter que le prix moyen augmente plus rapidement que le prix médian suggérant que les prix des propriétés les plus chères augmentent plus rapidement que ceux des propriétés moins chères.\"),\n",
    "    dcc.Graph(id='boxplot-prix'),# Graphique 3\n",
    "    html.P(\"Ces boxplot permettent de voir que la distribution des prix est inégale selon les quartiers et donc que le quartier d'appartenance a surement une influence sur le prix. Un clustering des quartiers peut donc être intéressant.\"),\n",
    "    html.P(\"Regardons maintenant si certaines variables ont une influence sur le prix.\"),\n",
    "    \n",
    "    # 1.2 Distribution des prix en fonction du statut de rénovation\n",
    "    html.H3(\"1.2 Distribution des prix en fonction du statut de rénovation\"),\n",
    "    html.P([\n",
    "    \"Les prochains graphiques ont été obtenus grâce au tableau de données : donc voici le lien : \",\n",
    "    html.A(\"Household-rcycling-borough.csv\",\n",
    "           href=\"https://data.london.gov.uk/download/household-waste-recycling-rates-borough/15ddc38a-0a37-4f69-98b5-e69e549b39d3/Household-rcycling-borough.csv\",\n",
    "           target=\"_blank\")\n",
    "    ]),\n",
    "    html.P(\"Ce graphique montre la distribution des prix selon que le logement a été rénové ou non.\"),\n",
    "    dcc.Graph(id='boxplot-renovation'),  # Graphique 4\n",
    "    html.P(\"On peut observer ici un résultat plutôt attendu :la médiane des prix des logements rénovés ou neufs est plus élevée que ceux qui sont vieux\"),\n",
    "\n",
    "    # 1.3 Taux de recyclage des logements de Londres\n",
    "    html.H3(\"1.3 Taux de recyclage des logements de Londres\"),\n",
    "    html.P(\"Ayant accès à des données de recyclage nous avons souhaité regarder si il y avait une tendance géographique de recyclage afin de savoir si c'était une donnée qui pourrait être pertinente pour le clustering de quartiers. \"),\n",
    "    dcc.Graph(id='graph-recyclage'),  # Graphique 5\n",
    "    html.P(\"On remarque que le taux de recyclage varie d'un quartier à l'autre. Il serait intéressant de le visualiser sur une carte afin de détecter d'éventuelles tendances géographiques.\"),\n",
    "\n",
    "    html.Iframe(id=\"recycling-map\",srcDoc=open(generate_recycling_map(), \"r\", encoding=\"utf-8\").read(),width=\"100%\",height=\"600px\",style={\"border\": \"none\"}),\n",
    "    html.P(\"Les habitants des quartiers extérieurs de Londres trient davantage leurs déchets que les individus habitant dans le centre. Le taux de recyclage pourra être pris en compte dans le clustering de quartiers.\"),\n",
    "    \n",
    "    # Section 2 : Clustering\n",
    "    html.H2(\"2. Clustering\"),\n",
    "    html.P(\"L'objectif ici est de trouver des clusters de quartiers, à l'aide du jeu de données que l'on peut charger sur le lien suivant : mettre le lien\"),\n",
    "    html.P(\"Ce jeu de données comprend les ventes, les prix médians et moyens des logements 3 fois par an de 1995 à 2022.\"),\n",
    "    html.P(\"À ce jeu de données on a ajouté d'autres jeux de données sur les taux de recyclage déjà utilisé précédemment ainsi qu'un autre jeu de données sur les logements disponibles (lien).\"),\n",
    "    html.P(\"Des modifications ont été faites sur le nom des colonnes et les datasets ont été fusionnés. Ensuite les données ont été normalisées. Le clustering a été appliqué à l'aide de la méthode des k-means avec le k optimal trouvé grâce à la méthode du coude.\"),\n",
    "    html.P(\"La méthode des k-means consiste à choisir k centroïdes initiaux, puis à assigner à chaque point restant le centroïde le plus proche. Puis le centroïde est recalculé. Une fois que l'algorithme converge on s'arrête.\"),\n",
    "    html.P(\"Ici 3 clusters ont été établis. Regardons sur la carte si ils sont répartis d'une certaine manière.\"),\n",
    "    dcc.Graph(id=\"map\", figure=fig_clusters),\n",
    "    html.P(\"On remarque que les quartiers du cluster 3 sont concentrés au centre de Londres, les quartiers de cluster 2 et 1 sont autour du centre et ceux du cluster 0 sont aux extrémités. Regardons les tendances des clusters selon les prix, le nombre de logements disponibles et le taux de recyclage.\"),\n",
    "    dcc.Graph(id=\"prix-cluster\", figure=fig_prix_cluster),\n",
    "    html.P(\"Concernant les prix, c'est le cluster 3 qui se distingue des autres, les quartiers du centre ont des logements plus chers que les autres.\"),\n",
    "    dcc.Graph(id=\"dispo-cluster\", figure=fig_dispo_cluster), \n",
    "    html.P(\"Concernant le nombre de logements disponibles le cluster 1 a une moyenne légèrement plus élevée que les autres. On ne peut pas tirer de conclusion pertinente concernant la répartition spatiale des logements disponibles.\"),\n",
    "    dcc.Graph(id=\"recy-cluster\", figure=fig_recy_cluster),\n",
    "    html.P(\"Enfin concernant le taux de recyclage, les quartiers du cluster 0 sont ceux qui recyclent le plus, tandis que ceux du cluster 3 sont ceux qui recyclent le moins, ce qui vient confirmer le graphe du taux de recyclage vu précédemment.\"),\n",
    "    html.P(\"Ainsi, ce clustering de quartiers, permet de se rendre compte qu'il y a des dynamiques différentes selon que l'on se trouve dans un quartier du centre ou excentré notamment en terme de prix et de recyclage.\"),\n",
    "    \n",
    "    #section 3 : classification \n",
    "    html.H2(\"3. Classification d'appartements par tranche de prix\"),\n",
    "    html.P(\"L'objectif ici est de de comparer différentes méthodes de classification sur le prix des appartements londoniens.\"),\n",
    "    html.P(\"Le jeu de données utilisé est london.csv, ce jeu recense 3480 appartements, et comprend donc 3480 lignes, qui une fois trié (séléction des quartiers de la métropole londonienne) comprend 2972 lignes. Les variables sont : 'House Type', 'Area in sq ft', 'No. of Bedrooms', 'No. of Bathrooms','No. of Receptions', 'Location', 'City/County'. Dans un premier temps nous allons faire un clustering de ces logements afin de créer des classes, puis grâce aux variables nous pourrons faire de la classification à l'aide de différentes méthodes et déterminer celle qui est la plus efficace.\",style={'text-align': 'justify'}),\n",
    "    \n",
    "    html.H3(\"3.1 Clustering à l'aide de la méthode des k-means\"),\n",
    "    html.P(\"Le prix étant une variable continue, nous avons dans un premier temps effectué un clustering à l'aide de la méthode des k-means sur les prix de vente des appartements afin de garder entre 4 et 8 catégories de prix.\"),\n",
    "    html.P(\"Ces tableaux montrent la répartition des données pour les différents clusters des différents clustering.\"),\n",
    "    html.H3(\"Sélectionnez un clustering\"),\n",
    "    \n",
    "    dcc.Dropdown(\n",
    "        id=\"cluster-dropdown\",\n",
    "        options=[{\"label\": key, \"value\": key} for key in cluster_data.keys()],\n",
    "        value=\"4 Clusters\",  # Valeur par défaut\n",
    "        clearable=False\n",
    "    ),\n",
    "\n",
    "    dash_table.DataTable(\n",
    "        id=\"cluster-table\",\n",
    "        style_table={'height': '300px', 'overflowY': 'auto'}),\n",
    "    html.P(\"En regardant les fréquences de chaque classe pour les différents clustering on peut remarquer que certaines classes sont très peu représentées. Cela induit souvent une mauvaise prédiction de classe en question et provoque donc une diminution de la perte de précisions de prédiction. Idéalement, il faudrait un recensement complet de tous les appartements de Londres, ce qui permettrait d'avoir des classes plus complètes, et d'avoir une meilleure précisiond de prédiction. Il faut maintenant tester différentes méthodes de classification avec tous les clustering sachant que plus on a de catégories meilleure sera la précision du prix puisque la fourchette de prix sera plus petite. Cependant, augmenter le nombre de clusters risque de faire augmenter le nombre d'erreurs et donc la précision de prédiction. Vérifions cette hypothèse.\",style={'text-align': 'justify'}),\n",
    "    html.H3(\"3.2 Comparaison de différentes méthodes de classification\"),\n",
    "    html.P(\"Afin de comparer la précision des méthodes, l'ensemble des données a été séparé en ensemble d'apprentissage/ test (80 % des données/ 20 % des données).\"),\n",
    "    html.P(\"Les modèles sont entrainés sur l'ensemble d'apprentissge et testés sur l'ensemble de test.\"),\n",
    "    html.P(\"La précision (Accuracy) est le quotient entre le nombre de réponses correctes et le nombre total de prédictions.\"),\n",
    "    html.P(\"Les différentes méthodes qui ont été comparées sont : l'arbre décision, la forêt aléatoire, l'algorithme light gbm et l'algorithme xgboost.\"),\n",
    "    html.P(\"Pour plus d'informations sur ces méthodes :\"),\n",
    "    html.A(\"Abre de décision\", href = \"https://www.ibm.com/fr-fr/think/topics/decision-trees\"),\n",
    "    html.A(\"Forêt aléatoire\", href = \"https://datascientest.com/random-forest-definition\"),\n",
    "    html.A(\"Xgboost\", href = \"https://xgboost.readthedocs.io/en/stable/\"),\n",
    "    html.A(\"LightGbm\", href = \"ttps://towardsdatascience.com/a-quick-guide-to-lightgbm-library-ef5385db8d10/\"),\n",
    "    \n",
    "    dcc.Graph(id=\"classification-results-graph\"),  # Graph for classification accuracy\n",
    "    \n",
    "    html.P(\"Ce graphique montre la précision des différentes méthodes de classifications pour chaque clustering\"),\n",
    "    html.P(\"La méthode random forest semble être la plus performante. LightGBM et XGBoost auraient sûrement été plus performants si nous avions eu plus de données.\"),\n",
    "    html.H3(\"3.3 Variables les plus importantes pour la classification par tranche de prix pour random forest\"),\n",
    "    \n",
    "    html.P(\"Ce graphique montre l'importance des variables pour dans la classification avec forêts aléatoires et 5 clusters\"),\n",
    "     # Ajouter le graphique de l'importance des variables pour les 5 clusters\n",
    "    dcc.Graph(\n",
    "        id=\"importance-variables-rf-5-clusters\",\n",
    "        figure=importance_fig  # La figure du graphique de l'importance des variables\n",
    "    ),\n",
    "    html.P(\"Les deux variables les plus déterminantes du prix des appartements londoniens sont la surface (constat évident) et la localisation (le quartier).\"),\n",
    "    html.H2(\"4. Conclusion\"),\n",
    "    html.P(\"Cette analyse du marché immobilier londonien a permis d’explorer plusieurs aspects du marché des logements, en mettant en évidence l’évolution des prix d’année en année, des comportements similaires entre quartiers et les facteurs influençant les prix des logements.\",style={'text-align': 'justify'}),\n",
    "    html.P(\" Dans un premier temps, l’analyse descriptive a confirmé une augmentation générale des prix à Londres depuis 1995, avec une différence entre les quartiers. L’impact de certaines variable a été osbervé, telles que la rénovation des logements et le taux de recyclage, variables qui semblent avoir des tendances géographiques.\",style={'text-align': 'justify'}),\n",
    "    html.P(\" Ensuite, le clustering des quartiers a permis d’identifier des regroupements, dont les quartiers partagent des caractéristiques communes. Cette segmentation a montré des tendances géographiques intéressantes. Enfin, la classification des appartements par tranche de prix a permis d’évaluer différentes méthodes d’apprentissage supervisé. Parmi les algorithmes testés (arbres de décision, forêts aléatoires, LightGBM et XGBoost), la forêt aléatoire a obtenu la meilleure précision (de peu). Les performances de LightGBM et XGBoost sont proches de celles de Random Forest et auraient été sûrement meilleures avec beaucoup plus de données. L’analyse de l’importance des variables a également confirmé que la surface et la localisation étaient les principaux déterminants du prix des appartements londoniens.\",style={'text-align': 'justify'}),\n",
    "    html.P(\"Cette étude pourrait être approfondie d’une part en ayant accès aux données de plus de logements, pour améliorer et généraliser les modèles prédictifs, notamment LightBGM et XGBoost qui devraient être plus performants que Random Forest. Des méthodes de régression ont aussi été essayées mais n’ont pas pu être abouties. Si les méthodes sont performantes elles pourraient permettre aux acheteurs ou aux vendeurs de déterminer le prix d’un bien de manière fiable.\",style={'text-align': 'justify'})\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Callback pour afficher l'évolution des prix de Londres\n",
    "@app.callback(\n",
    "    Output('prix-maisons-graph', 'figure'),\n",
    "    Input('prix-maisons-graph', 'id')\n",
    ")\n",
    "def update_london_graph(_):\n",
    "    df_borough = medianes[medianes[\"Area\"] == \"London\"]\n",
    "    fig = px.line(df_borough, x=\"Year\", y=\"Value\", color=\"Measure\",\n",
    "                  title=\"Évolution des prix des maisons à Londres\",\n",
    "                  labels={\"Value\": \"Prix (£)\", \"Year\": \"Année\"})\n",
    "    return fig\n",
    "\n",
    "# Callback pour mettre à jour le graphique par quartier\n",
    "@app.callback(\n",
    "    Output('graph-quartier', 'figure'),\n",
    "    [Input('dropdown-quartier', 'value')]\n",
    ")\n",
    "def update_graph(quartier):\n",
    "    df_quartier = medianes[medianes[\"Area\"] == quartier]\n",
    "    fig = px.line(df_quartier, x=\"Year\", y=\"Value\", color=\"Measure\",\n",
    "                  title=f\"Évolution des prix à {quartier}\",\n",
    "                  labels={\"Value\": \"Prix (£)\", \"Year\": \"Année\"})\n",
    "    return fig\n",
    "\n",
    "# Callback pour afficher le graphique des taux de recyclage\n",
    "@app.callback(\n",
    "    Output('graph-recyclage', 'figure'),\n",
    "    Input('graph-recyclage', 'id')\n",
    ")\n",
    "def update_recycling_graph(_):\n",
    "    fig = px.bar(moyenne_recyclage, x=\"Recycling_Rates\", y=\"Area\",\n",
    "                 title=\"Moyenne des taux de recyclage par quartier à Londres\",\n",
    "                 labels={\"Recycling_Rates\": \"Taux moyen de recyclage (%)\", \"Area\": \"Quartier\"},\n",
    "                 orientation=\"h\",  # Barres horizontales\n",
    "                 color=\"Recycling_Rates\", color_continuous_scale=\"viridis\")\n",
    "\n",
    "    fig.update_layout(yaxis=dict(categoryorder='total ascending'))  # Trier de haut en bas\n",
    "    return fig\n",
    "\n",
    "# Callback pour afficher le boxplot des prix par quartier\n",
    "@app.callback(\n",
    "    Output('boxplot-prix', 'figure'),\n",
    "    Input('boxplot-prix', 'id')\n",
    ")\n",
    "def update_boxplot(_):\n",
    "    fig = px.box(age_batiment, x=\"Neighborhood\", y=\"Price\",\n",
    "                 title=\"Distribution des prix par quartier\",\n",
    "                 labels={\"Price\": \"Prix (£)\", \"Neighborhood\": \"Quartier\"})\n",
    "    \n",
    "    fig.update_layout(xaxis_tickangle=-90)\n",
    "    return fig\n",
    "\n",
    "# Callback pour afficher le boxplot des prix par statut de rénovation\n",
    "@app.callback(\n",
    "    Output('boxplot-renovation', 'figure'),\n",
    "    Input('boxplot-renovation', 'id')\n",
    ")\n",
    "def update_renovation_boxplot(_):\n",
    "    fig = px.box(age_batiment, x=\"Building Status\", y=\"Price\",\n",
    "                 title=\"Distribution des prix en fonction du statut de rénovation\",\n",
    "                 labels={\"Price\": \"Prix (£)\", \"Building Status\": \"Statut de rénovation\"})\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('classification-results-graph', 'figure'),\n",
    "    Input('classification-results-graph', 'id')\n",
    ")\n",
    "def update_classification_results(_):\n",
    "    # Create a bar plot using Plotly\n",
    "    fig = px.bar(df_results, \n",
    "                 x=\"Découpage\", \n",
    "                 y=\"Accuracy\", \n",
    "                 color=\"Modèle\", \n",
    "                 title=\"Comparaison des méthodes de classification\",\n",
    "                 labels={\"Accuracy\": \"Précision\", \"Découpage\": \"Clustering\"},\n",
    "                 barmode=\"group\")\n",
    "\n",
    "    # Return the figure to be displayed\n",
    "    return fig\n",
    "    \n",
    "# Callback pour mettre à jour le tableau en fonction de la sélection\n",
    "@app.callback(\n",
    "    Output(\"cluster-table\", \"columns\"),\n",
    "    Output(\"cluster-table\", \"data\"),\n",
    "    Input(\"cluster-dropdown\", \"value\")\n",
    ")\n",
    "def update_table(selected_cluster):\n",
    "    df = cluster_data[selected_cluster]\n",
    "    return [{\"name\": col, \"id\": col} for col in df.columns], df.to_dict('records')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Exporter l'application Dash en HTML\n",
    "    with open(\"index.html\", \"w\") as f:\n",
    "        f.write(app.index_string)  # Écrire la chaîne générée dans le fichier\n",
    "\n",
    "    # Lancer le serveur Dash\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03735d0a-13c9-42c4-9ab5-c83f3a6a7008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13103fee-6ca7-49fa-857e-cdf0280f82c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
